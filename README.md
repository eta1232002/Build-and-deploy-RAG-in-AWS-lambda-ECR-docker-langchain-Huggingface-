# Document Question and Answering RAG APPLICATION

🚀 Welcom to the Document Question and Answering (Q&A) RAG Application! This project leverages cutting-edge technologies to create an efficient Q&A system. From model inference to deployment, I've got you covered.

## Overview

ℹ️ This project aims to streamline the process of extracting information from documents by answering user questions using the Retrieve and Generate (RAG) approach. It harnesses the power of AWS Bedrock, AWS AppRunner, AWS ECR, Langchain, FAISS, Docker, GitHub Actions, LangSmith, and Streamlit.

## 📈 Continuous Integration, Delivery, and Deployment

The project follows best practices for CI/CD/CD, leveraging GitHub Actions for automation:

- **Continuous Integration**: Ensures that every change is tested and validated(**GitHub**).
- **Continuous Delivery**: Automates the release process, making deployments frequent and reliable(**AWS ECR**).
- **Continuous Deployment**: Automatically deploys every validated change to production, ensuring fast and reliable updates(**AWS AppRunner**).


⚙️ **AWS Integration**: Leveraging AWS services like Bedrock, AppRunner, and ECR, I've created a scalable and reliable infrastructure for hosting our application.

🔑 **Environment Variables**: I've securely managed our project's deployment environment variables using GitHub Actions, ensuring a smooth deployment process.

## Technologies Used

🛠️ **AWS Bedrock**: Provides the foundational infrastructure for the application, ensuring scalability and reliability.

📦 **AWS AppRunner**: Simplifying container-based application deployment and management.

🐳 **Docker**: Containerizing our application for easy deployment and scalability.

🤖 **Langchain**: Harnessing the power of language models for advanced natural language processing tasks.

🔍 **FAISS**: Employing efficient similarity search for document retrieval.

🛡️ **GitHub Actions**: Automating our CI/CD pipeline for efficient development workflows.

🔗 **LangSmith**: Integrating powerful language models for inference.

🌐 **Streamlit**: Creating interactive and user-friendly web applications with ease.

## Model Inference and Embeddings

🧠 **Model Inference**: I utilize meta.llama2-13b-chat-v1 for model inference, ensuring accurate responses to user queries.

🔠 **Vector Embeddings**: Leveraging amazon.titan-embed-text-v1 for generating vector embeddings, enabling efficient document representation.

## 📧 Contact

For any questions or feedback, feel free to reach out!

- **WebSite**: [decodeai.in](https://decodeai.in)
- **GitHub**: [manoharpalanisamy](https://github.com/manoharpalanisamy)
- **Email**: [email@decodeai.in](mailto📧email@decodeai.in)

## Contributing

🤝 Contributions are welcome! Feel free to fork the repository and submit pull requests with your enhancements.

## License

📄 This project is licensed under the [MIT License](LICENSE), allowing for open collaboration and use.

Happy coding! 💻✨
